# 人工智能机器学习和深度学习

### Week5-8 谢明昊2018202108 吴翔宇2018202103

## 大纲

#### 第一章 AI简介

#### 第二章 机器学习简介

#### 第三章 机器学习中分类器

#### 第四章 深度学习简介

#### 第五章 深度学习：RNN和LSTM

#### 第六章 自然语言处理和强化学习

## 内容

### 第一章 AI简介

本章将对AI进行简要介绍，主要是对该多样化主题的广泛概述。与本书的其他章节不同，本入门章节是从技术内容上讲是“轻”的章节。但是，它很容易阅读，也值得浏览其内容。在本章末尾简要介绍了机器学习和深度学习，在后续章节中将对这两种方法进行更详细的讨论。

请记住，许多专注于AI的书都倾向于从计算机科学的角度以及传统算法和数据结构的角度来讨论AI。相比之下，这本书将AI视为机器学习和深度学习的“伞”，因此以粗略的方式将其讨论为其他各章的前身。

本章的第一部分首先讨论术语“人工智能”，确定智能存在性的各种潜在方法以及“强人工智能”和“弱人工智能”之间的区别。您还将了解图灵测试，这是一种著名的智力测验。

本章的第二部分讨论了一些AI用例以及神经计算，进化计算，NLP和生物信息学的早期方法。

本章的第三部分向您介绍AI的主要子领域，其中包括自然语言处理（使用NLU和NLG），机器学习，深度学习，强化学习和深度强化学习。

尽管本章未讨论特定于代码的示例，但本章的附件包含用于解决Red Donkey问题的基于Java的代码示例，以及解决魔方的基于Python的代码示例（需要Python 2.x）。

#### 什么是人工智能

“人工”一词的字面意思是合成词，通常具有次等替代词的负面含义。但是，人造物体（例如花）可以非常接近它们的对应物，有时，当它们没有任何维护要求（阳光，水等）时，它们可能是有利的。

相比之下，对智能的定义比对“人工”一词的定义更难以理解。R. Sternberg在关于人类意识的文章中提供了以下有用的定义：“==智能是个人从经验中学习，善于推理，记住重要信息以及应付日常生活需求的认知能力。== ”

您可能还记得标准测试中的问题，这些问题要求给定序列中的下一个数字，例如1、3、6、10、15、21。首先要注意的是，连续数字之间的差距增加了一个：从1开始到3，则增加为2，而从3到6，则增加为3，依此类推。根据这种模式，可能的答案为28。此类问题旨在衡量我们在识别模式中显着特征方面的熟练程度。

顺便说一句，“次序列”数字问题可能有多个答案。例如，序列2、4、8可能会建议16作为该序列中的下一个数字，如果生成公式为$2 ^ n$ ，这是正确的。但是，如果生成公式为$2^n+(n-1)*(n-2)*(n-3)$，则序列中的下一个数字为22（而不是16）。有很多公式可以将2、4和8匹配为数字的初始序列，但是下一个数字可以与16或22不同。

让我们回到R. Sternberg对情报的定义，并考虑以下问题：

•  您如何确定某人（某物）是否聪明？

•  动物聪明吗？

•  如果动物是聪明的，您如何衡量他们的智力？

==我们倾向于通过与人们互动来评估他们的智力：我们提出问题并观察他们的答案。尽管此方法是间接的，但我们经常依靠此方法来评估他人的情报。==

对于动物智力，我们还观察它们的行为进行评估。聪明的汉斯（Clever Hans）是一匹著名的马，大约在1900年生活在德国柏林，据称他精通算术，例如加数和计算平方根。

实际上，汉斯能够识别人的情绪，并且结合敏锐的听觉，当汉斯接近正确答案时，他可以感觉到听众的反应。有趣的是，汉斯在观众不在场的情况下表现不佳。您可能不愿意将Clever Hans的行为归因于智力。但是，在得出结论之前，请复习Sternberg的定义。

再举一个例子，一些生物仅在群体中表现出智力。尽管蚂蚁是简单的昆虫，并且它们孤立的行为很难保证将其包含在有关AI的文本中，但蚂蚁群体对复杂的问题却表现出非凡的解决方案。实际上，蚂蚁可以找出从巢到食物来源的最佳路线，如何搬运重物以及如何形成桥梁。因此，集体昆虫的智慧来自各个昆虫之间的有效交流。

脑质量和脑对身体质量的比率是智力的指标，在这两个指标中，海豚都比人类好。海豚的呼吸处于自愿控制之下，这可能导致大脑过多，以及海豚大脑的另一半轮流睡觉。海豚在动物自我意识测验（例如镜子测验）中得分很高，在这种测验中，海豚意识到镜子中的图像实际上是他们自己的图像。他们还可以执行复杂的技巧，因为海洋世界的游客可以作证。这说明了海豚记忆和执行复杂的身体运动序列的能力。

工具的使用是对智力的另一项试金石，常被用来将直立人与人类早期祖先分开。海豚也与人类有同样的特征：海豚在觅食时用深海海绵保护自己的嘴。因此，智力并不是人类独有的属性。许多生命形式都具有一定的智力。

现在考虑以下问题：==无生命的物体（例如计算机）是否可以拥有智能？==人工智能的既定目标是创建计算机软件和/或硬件系统，以表现出与人类可比的思维，换句话说，显示通常与人类智能相关的特征。

思考能力如何，机器可以思考吗？请记住，思维与智力之间是有区别的。思维是推理，分析，评估和制定思想观念的工具。因此，并不是每个有思维能力的人都是聪明的。智力也许类似于高效的思考。

许多人带着偏见来解决这个问题，他们说计算机是由硅和电源制成的，因此无法思考。在另一个极端，计算机的性能要比人类快得多，因此必须比人类更智能。真相很可能介于这两个极端之间。正如我们所讨论的，不同的动物物种具有不同程度的智力。但是，相比于开发用于动物的标准化IQ测试，我们更感兴趣的是确定机器智能的存在。也许拉斐尔说得最好：人工智能是使机器完成人类需要做的事情的科学。

##### 强AI与弱AI

当前有两个主要的关于AI的阵营。弱人工智能方法与麻省理工学院有关，它将任何表现出智能行为的系统视为人工智能的一个例子。该阵营着重于==程序是否正确执行，而不管工件是否以与人类相同的方式执行其任务。==电气工程，机器人技术及相关领域的AI项目的结果主要与令人满意的性能有关。

人工智能的另一种方法称为生物合理性，它与卡内基-梅隆大学相关。根据这种方法，==当人工制品表现出智能行为时，其性能应基于人类使用的相同方法。==例如，考虑一个具有听觉能力的系统：强AI的支持者可能会通过模拟人类的听觉系统来实现成功，而弱AI的支持者只会关注系统的性能。该模拟将包括耳蜗，耳道，耳膜和耳朵其他部分的等效物，每个等效物在系统中执行其所需的任务。

因此，弱AI的支持者仅根据性能来衡量其构建系统的成功率。他们坚持认为，存在的的理由人工智能研究的是解决疑难问题，无论他们实际上是如何解决的。

另一方面，强AI的支持者关心它们构建的系统的结构。他们坚持认为，仅凭具有启发式程序，算法和AI程序知识，计算机就可以具有意识和智力。如您所知，好莱坞制作了属于强AI阵营的各种电影（例如I，Robot和*Blade Runner*）。

#### 图灵测试

上一节提出了三个问题，而前两个问题已经解决：如何确定智力，动物是否聪明？第二个问题的答案不一定是“是”或“否”。有些人比其他人聪明，有些动物比其他人聪明。机器智能问题同样存在问题。

艾伦·图灵（Alan Turing）试图从作战角度回答情报问题。他想将功能（做什么）和实现（如何构建）分开。他设计了一种称为*Turing Test的*东西，将在下一部分中进行讨论。

##### 图灵测试的定义

艾伦·图灵（Alan Turing）提出了两个模仿游戏，其中一个人或一个实体的行为就好像他是另一个。在第一个游戏中，一个人（称为询问器）在一个房间里，窗帘穿过房间的中心。窗帘的另一边是一个人，审讯者必须确定是男人还是女人。询问者（性别无关）通过提出一系列问题来完成此任务。

这个游戏假设男人可能会在他的回应中撒谎，但是女人总是诚实的。为了使询问者无法从语音中确定性别，交流是通过计算机而不是通过口头表达的。如果是窗帘另一边的男人，并且成功欺骗了询问者，那么他将赢得模仿游戏。按照图灵测试的原始格式，男人和女人都坐在窗帘后面，审问者必须正确识别两者。

图灵可能基于此时期的一款流行游戏进行了这项测试，这甚至可能是他进行机器智能测试的动力。

如果您还不知道，埃里希·弗洛姆（Erich Fromm）是20世纪著名的社会学家和心理分析家，他们相信男人和女人平等，但不一定相同。例如，性别在颜色，花朵或购物时间方面的知识可能有所不同。区分男人和女人与智力问题有什么关系？图灵理解可能会有不同类型的思维，理解这些差异并容忍它们很重要。

##### 询问器测试

第二个游戏更适合研究AI。再次，审讯员在一个有窗帘的房间里。这次，一台计算机或一个人在幕后，机器扮演了男性的角色，有时还可以躺着。

另一方面，这个人一直是诚实的。询问器询问问题，然后评估响应以确定她是在与人还是在与机器通信。如果计算机成功欺骗了询问器，它将通过图灵测试，因此被认为是智能的。

#### 启发式

启发式方法可能非常有用，并且AI应用程序通常依赖于启发式方法的应用程序。==一个启发式本质上是解决问题的“经验法则”。换句话说，启发式是通常可以解决问题的一组准则。==将启发式算法与算法进行对比，后者是解决问题的规定规则集，其输出是完全可预测的。

启发式技术是一种用于寻找近似解的技术，该方法可以在其他方法过于耗时或过于复杂（或同时使用两种方法）时使用。使用启发式方法，可能会但不会保证有令人满意的结果，并且启发式方法在AI的早期特别流行。

日常生活中会出现各种启发。例如，许多人更喜欢使用启发式而不是询问驾驶方向。例如，当在晚上离开高速公路时，有时很难找到返回主干道的路。一个可能被证明是有用的启发是，当他们到达一个岔路口时，沿着有更多路灯的方向前进。对于捡回掉在地上的隐形眼镜，或者在拥挤的购物中心找停车位，你可能有一个最喜欢的策略。两者都是启发式的例子。

AI问题往往很大且计算复杂，而且通常无法通过简单的算法解决。人工智能问题及其领域趋向于体现大量的人类专业知识，尤其是如果采用强大的人工智能方法来解决。使用AI可以更好地解决某些类型的问题，而其他类型的问题更适合于涉及简单决策或精确计算以产生解决方案的传统计算机科学方法。让我们考虑一些示例：

•  医学诊断

•  使用带条形码扫描的收银机购物

•  自动取款机

•  两人游戏，如国际象棋和跳棋

医学诊断是科学领域，多年来受益于基于AI的贡献，特别是通过开发专家系统。专家系统通常构建在领域中，那里有大量的人类专业知识，并且存在许多通常采用以下形式的规则：if-condition-then-action。举一个简单的例子：如果您头痛，则服用两个阿司匹林并在早上打电话给我。

特别是，专家系统变得非常流行（并且非常有用），因为它们可以存储比人类头脑中能容纳的规则更多的规则。专家系统是产生全面而有效结果的最成功的AI技术之一。实际上，专家系统可以帮助人们做出更准确的决策（甚至“挑战”错误的选择）。

##### 遗传算法

达尔文的进化论是一种很有前途的范式，它涉及自然选择，其在自然界中以数千或数百万年的速度发生。相比之下，计算机内部的进化要比自然选择快得多。

遗传算法是一种启发式算法，可“模仿”自然选择的过程，其中涉及选择最适合的个体进行繁殖，以为其后代的后代生父。

让我们将AI的使用与动植物世界的进化过程进行比较和对比，在该过程中，物种通过自然选择，繁殖，突变和重组的遗传算子来适应环境。

遗传算法（GA）是通用领域中的一种特定方法，称为进化计算，这是AI的一个分支，其中提出的问题解决方案与动物适应现实世界的环境相适应。

#### 知识表示

当我们考虑与AI有关的问题时，代表性的问题变得很重要。获取和存储知识以对其进行处理并产生智能结果的AI系统还需要具有识别和表示该知识的能力。表示形式的选择是问题解决和理解的本质所固有的。

正如乔治·波利亚（George Polya）（著名的数学家）所说，一个好的表示选择几乎与针对特定问题设计的算法或解决方案一样重要。良好而自然的表述有助于快速而易于理解的解决方案。

作为代表选择的一个示例，请考虑著名的传教士和食人族问题，其目标是用船将三名传教士和三名食人族从西岸转移到一条河的东岸。在从西向东过渡的任何时候，您都可以通过选择适当的表示形式来查看求解路径。这个问题有两个约束条件：船在任何时候最多只能容纳两个人，任何岸上的食人族永远都不能超过传教士的人数。

##### 基于逻辑的解决方案

人工智能研究人员已将基于逻辑的方法用于知识表示和问题解决技术。特里·温诺格拉德（Terry Winograd）的《积木世界》（Blocks World）（1972）是使用逻辑为此目的开创性的例子，其中机械臂与桌面上的积木互动。该计划涵盖了语言理解和场景分析以及AI其他方面的问题。

此外，生产规则和生产系统用于构建许多成功的专家系统。生产规则和专家系统的吸引力在于清晰，简洁地表示启发式方法的可行性。结合这种方法，已经建立了成千上万的专家系统。

##### 语义网

语义网络是知识的另一种图形表示（尽管很复杂）。语义网络先于使用继承的面向对象语言（其中来自特定类的对象继承了超类的许多属性）。

使用语义网络的许多工作都集中在表示语言的知识和结构上。例子包括Stuart Shapiro SNePS （语义网处理系统）和Roger Schank 在自然语言处理中的工作。

存在用于知识表示的其他替代方法：图形方法对视觉，空间和运动等感官更具吸引力。最早的图形方法可能是状态空间表示，它显示系统的所有可能状态。

#### 人工智能与游戏

自二十世纪中叶以来，随着计算机的出现，通过培训计算机以玩和掌握复杂的棋盘游戏的挑战，计算机科学和编程技术水平得到了长足的进步。借助AI见解和方法论的应用而受益于计算机游戏的一些示例包括国际象棋，跳棋，围棋和奥赛罗。

游戏激发了人们对人工智能的发展和兴趣。1959年亚瑟·塞缪尔（Arthur Samuel）在跳棋游戏中的努力突显了早期的努力。他的程序基于五十种试探法的表格，并被用来与不同版本的自身进行对抗。在一系列比赛中失败的程序将采用获胜程序的试探法。它发挥了强大的跳棋，但从未掌握过游戏。

几个世纪以来，人们一直在尝试训练机器下棋。对国际象棋机器的痴迷可能源于一种普遍接受的观点，即需要智力才能很好地下棋。

1959年，Newell，Simon和Shaw开发了第一个真正的国际象棋程序，该程序遵循了Shannon-Turing范例。理查德·格林布拉特（Richard Greenblatt）的程序是第一个玩俱乐部级象棋的程序。在1970年代，计算机象棋程序稳步改进，直到该十年末达到专家级水平（相当于国际象棋锦标赛前1％的玩家）。

1983年，肯·汤普森（Ken Thompson）的美女（Belle）是第一个正式达到硕士水平的课程。随后是卡内基-梅隆大学的高科技公司的成功，作为第一个高级硕士（超过2400级）课程，该大学成功地实现了重要的里程碑。此后不久，“深思”程序（也来自卡耐基-梅隆大学）得到了发展，并成为第一个能够定期击败大师大师的程序。

当IBM在1990年代接手该项目时，Deep Thought演变为Deep Blue，而Deep Blue与世界冠军Garry Kasparov进行了六场比赛，后者于1996年在费城赢得一场比赛拯救了人类。1997年，Deeper与Deeper对抗蓝色（Deep Blue的继任者）卡斯帕罗夫（Kasparov）输了，国际象棋界动摇了。

在随后的对阵卡斯帕罗夫，克拉姆尼克和其他世界锦标赛级别的球员的六场比赛中，程序进行得不错，但不是世界锦标赛。尽管人们普遍认为这些程序可能仍然不如最优秀的人，但大多数人还是愿意承认，顶级程序与最有成就的人没有区别（如果有人想到图灵测试）。

1989年，埃德蒙顿艾伯塔大学的乔纳森·舍弗（Jonathan Schaeffer）开始了他的长期目标，即以他的程序“奇努克”（Chinook）征服跳棋比赛。在1992年与长期跳棋世界冠军马里恩·廷斯利（Marion Tinsley）进行的四十场比赛中，奇努克（Chinook）输了四分，平局三十四平。1994年，他们的比赛在经过6场比赛后并列，当时因健康原因，廷斯利不得不放弃比赛。从那时起，Schaeffer和他的团队一直在努力从游戏结束（全八张，结局更少）以及从一开始就解决跳棋。

其他使用AI技术的游戏包括步步高，扑克，桥牌，奥赛罗和围棋（通常称为新果蝇）。

##### AlphaZero的成功

谷歌创建了AlphaZero，这是一个基于AI的软件程序，使用自玩游戏来学习如何玩游戏。AlphaZero是Alpha Go的继任者，后者在2016年击败了世界上最好的人类Go玩家。AlphaZero在Go游戏中 轻松击败了Alpha Go。

此外，在学习了国际象棋规则之后，AlphaZero进行了自我训练（再次使用自玩游戏），并且一天之内就成为了世界上顶级的国际象棋手。AlphaZero可以击败任何人类下象棋者以及任何下象棋的计算机程序。

真正有趣的一点是，AlphaZero制定了自己的下棋策略，这不仅与人类不同，而且还涉及被认为违反直觉的棋步。

不幸的是，AlphaZero无法告诉我们它是如何开发出一种优于以前开发的下棋方法的策略的。由于AlphaZero是100％自学的，并且是世界上排名最高的棋手，因此AlphaZero是否有资格成为聪明人？

#### 专家系统

自从人工智能存在以来，专家系统就是人们研究的领域之一，这是人工智能取得巨大成功的一门学科。专家系统具有许多特征，使其成为AI研究与开发所希望的。其中包括知识库与推理引擎的分离，超过其任何或所有专家的总和，知识与搜索技术的关系，推理和不确定性。

最早且最常被引用的系统之一是启发式DENDRAL。其目的是根据质谱图鉴定未知化合物。DENDRAL是由斯坦福大学开发的，目的是对火星土壤进行化学分析。它是最早说明在特定学科中对领域专家知识进行编码的系统之一。

也许最著名的专家系统是斯坦福大学（1984）的MYCIN。开发了Mycin来促进血液传染病的研究。然而，比其领域更为重要的是Mycin为设计所有后续基于知识的系统而建立的示例。它有400多个规则，最终被用来为斯坦福医院的居民提供培训对话。

1970年代，PROSPECTOR（也在斯坦福大学（Stanford University））被开发用于矿物勘探。PROSPECTOR还是使用推理网络的早期且有价值的例子。

1970年代后出现的其他著名且成功的系统是XCON（具有约10,000条规则），其开发目的是帮助在VAX计算机上配置电路板。GUIDON，一种辅导系统，是Mycin的分支；TEIRESIAS，Mycin的知识获取工具；和HEARSAY I和II，这是使用Blackboard Architecture进行语音理解的主要示例。

道格·列纳特（Doug Lenat）的AM（人工数学家）系统是 1970年代研发工作的另一个重要成果，也是不确定条件下的推理的Dempster-Schafer理论以及Zadeh在模糊逻辑中的工作。

自1980年代以来，==在配置，诊断，指令，监视，计划，预后，补救和控制等领域已开发了成千上万的专家系统。==如今，除了独立的专家系统外，许多专家系统还被嵌入到其他软件系统中来进行控制，包括医疗设备和汽车中的系统（例如，牵引力控制何时应用于汽车中？）。

此外，许多专家系统的外壳，例如Emycin，OPS，EXSYS和CLIPS，已成为行业标准。还开发了许多知识表示语言。如今，许多专家系统在后台进行工作以增强日常体验，例如在线购物车。

#### 神经计算

McCulloch和Pitts进行了神经计算的早期研究，因为他们试图了解动物神经系统的行为。他们的人工神经网络（ANN）模型有一个严重的缺点：它不包含学习机制。

弗兰克·罗森布拉特（Frank Rosenblatt）开发了一种称为“感知器学习规则”的迭代算法，用于在==单层网络==（所有神经元都直接连接到输入的网络）中找到合适的权重。Minsky和Papert声明某些问题无法通过单层感知器解决，例如异或（XOR）功能可能严重阻碍了这一新兴学科的研究。这项声明发布后，联邦政府立即大幅削减了对神经网络研究的资助。

在1980年代初，霍普菲尔德（Hopfield）的工作使该领域再次活跃起来。他的==异步网络模型（Hopfield网络）==使用能量函数来近似解决NP完全问题。

1980年代中期还见证了==反向传播==（通常称为*backprop*）的发现，这是一种适用于多层网络的学习算法。通常使用基于反向传播的网络来预测道琼斯平均值，并在光学字符识别系统中读取印刷的材料。

神经网络也用于控制系统。ALVINN是卡内基梅隆大学的一个项目，在该项目中，后向传播网络可感测高速公路并帮助操纵Navlab车辆。

这项工作的一个即时应用是，当车辆偏离高速公路车道时，警告因缺乏睡眠、过量饮酒或其他情况而受损的司机。展望未来，我们希望，有一天，类似的系统将驾驶车辆，使我们可以自由地阅读报纸和打电话，充分利用额外的空闲时间。

#### 进化计算

==遗传算法==通常被归类为进化计算。遗传算法使用概率和并行性来解决组合问题（也称为优化问题），这是约翰·霍兰德（John Holland）开发的一种方法。

但是，进化计算不仅与优化问题有关。Rodney Brooks曾任麻省理工学院计算机科学和AI实验室的负责人。他成功地创建了人类级人工智能的方法，他恰当地将其称为AI研究的圣杯，他放弃了对基于符号方法的依赖。后一种方法依赖于启发式和代表性范例的使用。

在他看来，==智能系统可以在多层中设计==，在多层中较高层依赖于底层。例如，如果你想建造一个能够避开障碍物的机器人，那么避障程序就会建立在一个较低的层次上，这个层次只负责机器人的移动。

brooks坚持认为，情报是通过特工与其环境的相互作用而产生的。他最为人所知的可能是在他的实验室里制造的类似昆虫的机器人，这些机器人体现了这种智能哲学，在这种哲学中，一群自主的机器人与它们的环境以及彼此之间进行互动。

#### 自然语言处理

如果我们希望构建智能系统，那么很自然地要求我们的系统具有语言理解功能。这是许多早期从业人员都很好理解的公理。Eliza是一个著名的早期应用程序，由麻省理工学院的计算机科学家Joseph Weizenbaum（与斯坦福大学精神病学家Kenneth Colby合作）开发。

Eliza的目的是模仿卡尔·罗杰斯学校的心理医生所扮演的角色。例如，如果用户键入“我感到很累”，则Eliza是向后传播应用程序，可以学习英语文本的正确发音。据称它能以95％的准确度发出英语声音。显然，由于英语单词的发音（例如，*rough*和*through*）与从其他语言（例如，*pizza* 和*fizzy*）派生的单词的内在矛盾而引起了问题。

特里·威诺格拉德（Terry Winograd）编写了另一个著名的程序，该程序以ETAOIN SHRDLU对中的第二组字母命名，这是线性印刷机上英语中最常用的字母。Winograd的程序可能会回答：“您说您感到疲倦。告诉我更多。” “对话”将以这种方式继续进行，而机器就对话的独创性而言几乎没有贡献。一位活着的心理分析师可能会以这种方式行事，希望患者能发现自己的真实（也许是隐藏的）感觉和挫败感。同时，Eliza仅使用模式匹配来伪装类似人的交互。

奇怪的是，维岑鲍姆对他的学生（以及整个公众）对与Eliza互动的强烈兴趣感到不安，尽管他们完全意识到Eliza只是一个程序。同时，Colby仍然致力于该项目，并继续编写了一个成功的程序，称为DOCTOR。

尽管Eliza对自然语言处理（NLP）的贡献很小，但==它是一种假装拥有可能是我们独特之处的最后遗迹的软件==，我们感受情感的能力。当人与机器之间的界线（例如：机器人）之间的界限变得不太清晰（可能在大约五十年之内）并且这些机器人会变得不那么凡人而更像不朽时，会发生什么？

最近，已经开发了包括Cog，Kismet和Paro在内的数种MIT机器人，它们具有伪装人类情感并引起与之互动的人的情感反应的超强能力。Turkle研究了这些机器人与养老院中的儿童和老年人之间的关系。涉及真正情感和关怀的关系。Turkle谈到可能需要重新定义“关系”一词， 以包括人们与这些所谓的“关系工件”的相遇。她仍然有信心，但是，这样的关系永远不会取代只能在每天面对死亡的人类之间发生的联系。

Winograd的Blocks World涉及一个能够实现各种目标的机械臂。例如，如果要求SHRDLU提起上面有一个小绿色块的红色块，它知道必须先移除绿色块，然后才能举起红色块。与Eliza不同，SHRDLU能够理解英语命令并做出适当响应。

HEARSAY是一个雄心勃勃的语音识别程序，它采用了黑板结构，其中用于语言的各个组成部分（如语音和短语）的独立知识源（代理）可以自由地进行交流。语法和语义都用于修剪不可能的单词组合。

HWIM（发音为“ whim”，是“听我的意思”的简称）项目使用增强的过渡网络来理解口语。它涉及旅行预算管理的词汇为1,000个单词。也许这个项目在范围上过于雄心勃勃，因为它的表现不如HEARSAY II。

解析对于这些自然语言程序的成功至关重要。SHRDLU采用了上下文无关的语法来帮助解析英语命令。上下文无关的语法提供了一种用于处理符号字符串的语法结构。但是，为了有效处理自然语言，还必须考虑语义。

一个解析树提供了组成句子的单词之间的关系。例如，许多句子可以分解为主语和谓语。主题可以分解为名词短语，然后是介词短语，依此类推。本质上，解析树给出了语义，即句子的含义。

这些==早期语言处理系统==中的每一个都在某种程度上利用了世界知识。然而，在1980年代后期，NLP取得进展的==最大绊脚石==是常识知识问题。例如，尽管在NLP和AI的特定领域构建了许多成功的程序，但这些程序经常被批评为微型世界，这意味着这些程序没有一般的，现实世界的知识或常识。例如，一个程序可能对特定情况有很多了解，例如在餐厅点菜，但是却不知道服务员是否还活着，或者他们通常是否会穿任何衣服。在过去的25年中，道格拉斯·莱纳特（Douglas Lenat）位于德克萨斯州奥斯汀市的MCC的研究人员正在建立最大的常识性知识库，以解决此问题。

NLP经历了一些有趣的发展。在初始阶段之后（如本节前面所述），NLP依靠统计数据来管理句子的语法分析树。Charniak描述了如何扩展无上下文语法（CFG），以使每个规则都有关联的概率。这些相关的概率可以从Penn树库中获取，该树库包含超过一百万个英语单词，这些单词已被手动解析，大部分来自《华尔街日报》。Charniak演示了这种统计方法如何成功地从《纽约时报》的首页获得了一个句子的解析（即使对于大多数人来说也没有什么小事）。

在NLP的发展的下一步涉及到深层学习架构称为RNNs，LSTMs和双向LSTMs，这是在第5章讨论的最新架构被称为变压器，这是由谷歌在2017年BERT开发基于变压器（以及“注意力”），并且是目前可用于解决NLP任务的最强大的开源系统之一。NLP的另一种方法涉及深度强化学习（在第6章中进行了简要讨论）。

#### 生物信息学

生物信息学是一门新兴学科，涉及计算机科学的算法和技术在分子生物学中的应用。它主要涉及==生物数据的管理和分析==。在结构基因组学中，人们尝试为每种观察到的蛋白质指定结构。自动发现和数据挖掘可以帮助实现这一目标。

Juristica和Glasgow证明了基于案例的推理如何帮助发现每种蛋白质的代表性结构。格拉斯哥，尤里西卡和罗斯特在AAAI关于AI和生物信息学的AAAI专刊中于2004年发表的调查文章中 指出：“可能最近生物信息学活动中增长最快的领域是微阵列数据分析。”

对于微生物学家来说，可获得的数据种类繁多，数量不胜其烦。他们被要求仅基于庞大的数据库来了解分子序列，结构和数据。许多研究人员认为，来自知识表示和机器学习的AI技术也将证明是有益的。

本章的下一部分将快速介绍AI的主要部分，包括机器学习和深度学习。

#### 人工智能的主要部分

本书的后续章节深入探讨了AI的各个重要部分，其中包括：

•  ML（机器学习）

•  DL（深度学习）

•  NLP（自然语言处理）

•  RL（强化学习）

•  DRL（深度强化学习）

传统的AI（二十世纪）基于规则集合，这导致了1980年代的专家系统。传统的AI也涉及LISP，它是由John McCarthy（1956年第一次正式AI会议的成员之一）创建的。

传统的AI主要是==与条件逻辑结合的一组规则==，这对于1980年代开发的功能强大的专家系统也是如此。但是，用于决策的基于规则的系统可能涉及成千上万条规则。甚至简单的对象也需要许多规则：尝试提出一组定义椅子，桌子甚至只是苹果的规则。传统的AI有一些明显的限制，主要是因为需要的规则数量。

##### 机器学习

大约在20世纪中叶，机器学习（人工智能的一个子集）主要依靠数据来优化和“学习”如何执行任务，通常伴随着新的或改进的算法，例如线性回归，k-NN，决策树，随机森林和SVM；除了线性回归，其他所有算法都是分类器。

如您所见，机器学习是一个充满活力的领域，其中包括其他子领域。

由于数据（而非规则）在机器学习中非常重要，因此通常是以下类型之一：

•  监督学习（大量标记数据）

•  半监督学习（大量带有部分标签的数据）

•  无监督学习：大量数据，聚类

•  强化学习：试用，反馈和改进

根据Coursera的联合创始人Ng的说法，“所有机器学习中的99％受监督。”

除了分类数据外，机器学习算法还可以分类为以下主要类型：

•  分类器（用于图像，垃圾邮件，欺诈等）

•  回归（股票价格，房屋价格等）

•  聚类（无监督分类器）

##### 深度学习

机器学习的一个重要子领域是深度学习，它也起源于二十世纪中叶。深度学习架构依赖于感知器作为神经网络的基础，通常涉及大型或海量数据集。这样的体系结构还涉及启发式方法和经验结果。如今，对于某些图像分类，深度学习可以超越人类。

虽然机器学习涉及MLP（多层感知器），但深度学习引入了具有新算法和新架构（例如卷积神经网络，RNN和LSTM）的深度神经网络。

##### 强化学习

强化学习（也是机器学习的一个子集）涉及试错法，以最大程度地提高所谓代理的报酬。深度强化学习将深度学习与强化学习的优势结合在一起。特别是，强化学习中的主体被神经网络取代。

深度强化学习在许多不同领域中都有应用，其中最受欢迎的三个是：

•  游戏（围棋，国际象棋等）

•  机器人技术

•  NLP

在游戏中使用强化学习的一些著名且成功的示例包括：

•  Alpha Go（混合RL）

•  Alpha Zero（完整的RL）

•  通常涉及贪婪算法

•  深度RL：将深度学习和RL相结合

##### 机器人技术

机器人以多种方式进入了我们的个人和职业生活，包括：

•  手术（协助外科医生）

•  放射学（检测癌症）

•  药物管理

•  宗教比较理论

•  法律/房地产/军事/科学

•  喜剧（包括单口相声）

•  音乐（指挥乐队）

•  餐厅（美食）

•  协调的舞蹈队

•  许多其他领域

机器人卡车司机正在转移工作，但它们也有优势：他们唯一的成本就是维护机器。此外，机器人并不会像人类那样分散注意力，他们不会从事会导致事故的活动，也不需要薪水或任何休假时间。尽管机器人取得了令人惊讶的成就，但《星际迷航》的角色数据仍然只是一个梦想。

NLP是计算机科学和AI领域，涉及计算机与人类语言之间的交互。在早期，NLP涉及基于规则的技术或统计技术。NLP和机器学习可以处理/分析大量自然语言数据，其中计算机程序执行该处理。

机器学习技术可以解决许多NLP任务。NLP涉及的一些感兴趣的领域包括：

•  语言之间的翻译

•  从文本中查找有意义的信息

•  文件汇总

•  检测仇恨言论

尽管机器学习具有所有进步和优势，等等，但仍有一些问题需要解决。一个问题是职业偏见：一个人工智能系统推断白人是医生，白人是家庭主妇。另一个问题涉及发现性别偏见。例如，在Wikipedia（大约2018年）中，其18％的传记是女性，而Wikipedia的编辑中84％至90％是男性。

在下一篇文章中分析的另一个问题涉及数据偏差与算法偏差：

*https://www.forbes.com/sites/charlestowersclark/2018/09/19/can-we-*

#### 使人工智慧负责

最后，还有AI与伦理之间的相互作用问题，其中包括一些发人深省的问题（例如失业和机器人权利）。以下文章包含道德问题的详细列表：

*https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-inartificial-intelligence/*



### 第二章 机器学习

本章介绍了机器学习中的众多概念，例如特征选择，特征工程，数据清理，训练集和测试集。

本章的第一部分简要讨论了机器学习和准备数据集通常所需的步骤顺序。这些步骤包括可以使用各种算法执行的“功能选择”或“功能提取”。

第二部分描述了您可能会遇到的数据类型，数据集中的数据可能出现的问题以及如何纠正它们。当您执行训练步骤时，您还将了解“伸出”和“折叠”之间的区别。

本章的第三部分简要讨论了线性回归所涉及的基本概念。尽管线性回归是200年前开发的，但该技术仍然是解决（尽管很简单）统计和机器学习问题的“核心”技术之一。实际上，在Python和TensorFlow中实施了一种称为“均方误差”（MSE）的技术，该技术用于为2D平面（或更高尺寸的超平面）中的数据点找到最合适的线，以最大程度地减少所谓的稍后讨论的“成本”功能。

本章的第四部分包含使用NumPy中的标准技术进行线性回归任务的其他代码示例。因此，如果您熟悉此主题，则可以快速浏览本章的前两节。第三部分介绍如何使用Keras求解线性回归。

要记住的一点是，提到了一些算法而没有深入研究它们的细节。例如，与监督学习有关的部分包含一个算法列表，这些算法将在与分类算法有关的部分的本章后面出现。列表中以粗体显示的算法是本书中更感兴趣的算法。在某些情况下，下一章将详细讨论算法。否则，您可以在线搜索有关本书中未详细讨论的算法的其他信息。

#### 什么是机器学习？

从高级的角度讲，机器学习是AI的一个子集，它可以解决“传统”编程语言无法完成或过于繁琐的任务。电子邮件的垃圾邮件过滤器是机器学习的早期示例。机器学习通常会取代旧算法的准确性。

尽管机器学习算法多种多样，但可以说数据比所选算法更重要。数据可能会出现许多问题，例如数据不足，数据质量差，数据不正确，数据丢失，不相关的数据，重复的数据值等等。在本章的后面，您将看到解决许多与数据有关的问题的技术。

如果您不熟悉机器学习术语，则数据集是数据值的集合，可以采用CSV文件或电子表格的形式。每列称为功能，每行是一个数据点，其中包含每个功能的一组特定值。如果数据集包含有关客户的信息，则每一行都与特定客户有关。

##### 机器学习的类型

您将遇到三种主要的机器学习类型（也可以将它们组合）：

•  监督学习

•  无监督学习

•  半监督学习

==监督学习==意味着数据集中的数据点具有标识其内容的标签。例如，MNIST数据集包含28x28个PNG文件，每个文件都包含一个手绘数字（即0到9，包括0和9）。每个数字为0的图像的标签均为0；每个数字为1的图像都带有标签1；所有其他图像均根据这些图像中显示的数字进行标记。

再举一个例子，泰坦尼克号数据集中的列是有关乘客的特征，例如他们的性别，舱位，机票价格，乘客是否幸存等等。每行包含有关单个乘客的信息，如果该乘客幸存，则包括值1。MNIST数据集和Titanic数据集涉及分类任务：目标是基于训练数据集训练模型，然后预测测试数据集中每一行的类别。

通常，用于分类任务的数据集具有少量可能的值：0到9范围内的九个数字之一，四只动物（狗，猫，马，长颈鹿）之一，两个值（幸存或灭亡）之一，已购买还是未购买）。根据经验，如果结果数量可以在下拉列表中“合理地”显示，则可能是分类任务。

对于包含房地产数据的数据集，每行包含有关特定房屋的信息，例如卧室的数量，房屋的平方英尺，浴室的数量，房屋的价格等。在此数据集中，房屋价格是每一行的标签。请注意，可能的价格范围太大，无法在下拉列表中“合理地容纳”。房地产数据集涉及回归任务：目标是基于训练数据集训练模型，然后预测测试数据集中每个房屋的价格。

==无监督学习==涉及未标记的数据，通常是聚类算法的情况（稍后讨论）。下面列出了一些涉及聚类的重要无监督学习算法：

•  k-Means

•  层次聚类分析（HCA）

•  期望最大化

下面列出了一些涉及降维的重要无监督学习算法（稍后将详细讨论）：

•  PCA（主成分分析）

•  内核PCA

•  LLE（局部线性嵌入）

====•  t-SNE（t分布随机邻居嵌入）

还有另一项非常重要的无监督任务称为==异常检测==。此任务与欺诈检测和检测异常值有关（稍后将详细讨论）。

==半监督学习==是监督学习和无监督学习的结合：有些数据点被标记，有些没有标记。一种技术涉及使用标记的数据对未标记的数据进行分类（即标记），然后可以应用分类算法。

#### 机器学习算法的类型

机器学习算法主要有三种类型：

•  回归（例如：线性回归）

•  分类（例如：k最近邻）

•  聚类（例如：kMeans）

==回归==是一种预测数值量的监督学习技术。回归任务的一个示例是预测特定股票的价值。请注意，此任务不同于预测明天（或其他某个未来时间段）特定股票的价值是否会增加或减少。回归任务的另一个示例涉及预测房地产数据集中的房屋成本。这两个任务都是回归任务的示例。

机器学习中的回归算法包括线性回归和广义线性回归（在传统统计中也称为多元分析）。

==分类==也是一种有监督的学习技术，但它是用于预测分类数量的。分类任务的一个示例是检测垃圾邮件的发生，欺诈或确定PNG文件（例如MNIST数据集）中的数字。在这种情况下，数据已被标记，因此您可以将预测与分配给给定PNG的标签进行比较。

机器学习中的分类算法包括以下算法列表（在下一章中将对其进行详细讨论）：

•  决策树（单个树）

•  随机森林（多棵树）

•   kNN（k最近邻居）

•  Logistic回归（尽管其名称）

•  朴素贝叶斯

•  SVM（支持向量机）

一些机器学习算法（例如SVM，随机森林和kNN）支持回归和分类。对于SVM，此算法的scikit-learn实现提供两个API：用于分类的SVC和用于回归的SVR。

前面的每个算法都涉及一个在数据集上训练的模型，然后使用该模型进行预测。相比之下，随机森林由多个独立的树组成（数目由您指定），并且每个树都对要素的值进行预测。如果特征是数字，则采用均值或众数（或执行其他计算）以确定“最终”预测。如果特征是分类的，则使用模式（即，最频繁出现的类）作为结果；否则，使用默认模式。如果是平局，您可以随机选择其中之一。

==聚类==是一种用于将相似数据分组在一起的无监督学习技术。群集算法将数据点放置在不同的群集中，而不知道数据点的性质。将数据分成不同的群集后，可以使用SVM（支持向量机）算法进行分类。

机器学习中的聚类算法包括以下内容（其中一些是彼此的变体）：

•  k-Means

•  平均移位

•  层次聚类分析（HCA）

•  期望最大化

请记住以下几点。首先，k-Means中的k是一个超参数，并且它通常是一个奇数到两个类之间的关系避免。接下来，均值漂移算法是一个变化的k均值算法，它不要求你指定K值。实际上，均值漂移算法确定了最佳的簇数。

但是，该算法不能很好地用于大型数据集。

##### 机器学习任务

除非您已经清理过数据集，否则您需要检查数据集中的数据以确保其处于适当的状态。数据准备阶段包括1）检查行（“数据清理”）以确保它们包含有效数据（这可能需要特定领域的知识），以及2）检查列（特征选择或特征提取）以确定是否可以保留只有最重要的列。

下面显示了机器学习任务序列的高级列表（可能不需要其中的一些）：

•  获取数据集

•  数据清理

•  功能选择

•  降维

•  算法选择

•  训练与测试数据

•  训练模型

•  测试模型

•  微调模型

•  获取模型的指标

首先，您显然需要获取任务的数据集。在理想情况下，该数据集已经存在；否则，您需要从一个或多个数据源（例如CSV文件，关系数据库，no-SQL数据库，Web服务等）中剔除数据。

其次，您需要执行==数据清理==，可以通过以下技术进行清理：

•  缺失价值率

•  低方差滤波器

•  高相关滤波器

通常，数据清理涉及检查数据集中的数据值，以便解决以下一个或多个问题：

•  修正错误的值

•  解决重复值

•  解决缺失值

•  决定如何处理异常值

如果数据集的缺失值太多，请使用缺失值比率技术。在极端情况下，您可能可以删除具有大量缺失值的要素。使用低方差过滤器技术从数据集中识别和删除具有恒定值的要素。使用“高相关性”过滤器技术查找高度相关的要素，这会增加数据集中的多重共线性：可以从数据集中删除此类要素（但在执行此操作之前，请与您的领域专家联系）。

根据您的背景和数据集的性质，您可能需要与一位领域专家合作，该专家对数据集的内容有深刻的了解。

例如，您可以使用统计值（平均值，众数等）将不正确的值替换为合适的值。重复值可以类似的方式处理。您可以在数字列中用零，最小值，平均值，众数或最大值替换缺失的数值。您可以使用分类列的模式替换缺少的分类值。

如果数据集中的行包含一个离群值，则可以选择三个选项：

•  删除行

•  保持排

•  将异常值替换为其他值（平均值？）

当数据集包含异常值时，您需要基于特定于给定数据集的领域知识做出决策。

假设数据集包含与库存相关的信息。如您所知，1929年股市崩盘，您可以将其视为异常值。这种情况很少见，但可以包含有意义的信息。顺便说一句，财富在20有些家庭源届世纪是基于购买的股票大量是大萧条时期非常低的价格。

#### 特征工程，选择和提取

除了创建数据集并“清理”其值外，您还需要检查该数据集中的要素，以确定是否可以减少该数据集的维数（即列数）。这样做的过程涉及三种主要技术：

•  特征工程

•  特征选择

•  特征提取（又称特征投影）

==特征工程==是根据现有特征的组合确定一组新特征的过程，以便为给定任务创建有意义的数据集。即使在相对简单的数据集的情况下，此过程通常也需要领域专家。特征工程可能是乏味且昂贵的，并且在某些情况下，您可能会考虑使用自动特征学习。创建数据集后，最好执行特征选择或特征提取（或同时执行这两项操作）以确保您拥有高质量的数据集。

==特征选择==也称为变量选择，属性选择或变量子集选择。特征选择涉及选择数据集中相关特征的子集。本质上，特征选择涉及选择数据集中的“最重要”特征，这提供了以下优点：

•  减少训练时间

•  更简单的模型更易于解释

•  避免维数的影响

•  由于减少了过拟合（“减少差异”），因此泛化效果更好

特征选择技术通常用于特征较多且样本（或数据点）相对较少的域中。请记住，低价值功能可能是多余的，也可能是无关的，这是两个不同的概念。例如，一个相关的功能与另一个高度相关的功能结合使用时可能是多余的。

特征选择可以涉及三种策略： 过滤器策略（例如，信息增益），包装器策略（例如，以准确性为指导的搜索）和嵌入式策略（预测误差用于确定在开发模型时是否包含或排除特征）。另一个有趣的一点是，特征选择对于回归以及分类任务也可能有用。

==特征提取==从产生原始特征组合的函数中创建新特征。相反，特征选择涉及确定现有特征的子集。

特征选择和特征提取均会导致给定数据集的降维，这是下一部分的主题。

#### 降维

降维指的是减少数据集中特征数量的算法：因此称为“降维”。正如您将看到的，有许多可用的技术，它们涉及特征选择或特征提取。

此处列出了使用特征选择来执行降维的算法：

•  后向功能消除

•  转发功能选择

•  因素分析

•  独立成分分析

此处列出了使用特征提取执行降维的算法：

•  主成分分析（PCA）

•  非负矩阵分解（NMF）

•  内核PCA

•  基于图的内核PCA

•  线性判别分析（LDA）

•  广义判别分析（GDA）

•  自动编码器

以下算法结合了特征提取和降维功能：

•  主成分分析（PCA）

•  线性判别分析（LDA）

•  典型相关分析（CCA）

•  非负矩阵分解（NMF）

这些算法可以在数据集上使用聚类或其他算法（例如kNN）之前的预处理步骤中使用。

另一组算法涉及基于投影的方法，其中包括t分布随机邻居嵌入（t-SNE）以及UMAP。

本章讨论PCA，您可以执行在线搜索以查找有关其他算法的更多信息。

##### PCA

主成分是数据集中初始变量的线性组合的新成分。此外，这些组件是不相关的，最有意义或最重要的信息包含在这些新组件中。

PCA有两个优点：1）由于功能少得多而减少了计算时间； 2）最多有三个组件时可以绘制组件图形。如果您有四个或五个组件，则将无法直观地显示它们，但是您可以选择三个组件的子集进行可视化，并可能对数据集有更多了解。

==PCA使用方差作为信息的度量==：方差越大，组成部分越重要。实际上，只是稍微向前跳一下：PCA确定协方差矩阵的特征值和特征向量（稍后讨论），并构造一个新矩阵，其列为特征向量，根据最左边列中的最大特征值从左到右排序，直到最右边的特征向量也具有最小的特征值。

##### 协方差矩阵

提醒一下，称为随机变量X方差的统计量定义如下：
$$
variance(X)=[\sum(X-Xbar)^2]/n
$$
协方差矩阵C是$n*n$矩阵，其主对角线上的值是变量X1，X2，...的方差。。。，Xn。C的其他值是每对变量Xi和Xj的协方差值。 

变量X和Y的协方差公式是变量方差的概括，公式如下所示：
$$
covariance(X,Y)=[\sum(X-Xbar)*(Y-Ybar)]/n
$$
注意，您可以反转项乘积的顺序（乘法是可交换的），因此协方差矩阵C是对称矩阵：
$$
covariance(X,Y)=covariance(Y,X)
$$
PCA计算协方差矩阵A的特征值和特征向量。

#### 使用数据集

除了清除数据外，还需要执行其他几个步骤，例如选择训练数据与测试数据，以及决定在训练过程中使用“保留”还是交叉验证。

在后续部分中提供了更多详细信息。

##### 训练数据与测试数据

在完成了本章前面介绍的任务（即数据清理和降维）之后，您就可以将数据集分为两部分了。第一部分是==训练集==，用于训练模型，第二部分是==测试集==，用于“推理”（进行预测的另一个术语）。确保您符合以下测试集准则：

•  集合足够大，可以产生具有统计意义的结果

•  代表整个数据集

•  切勿训练测试数据

•  不要测试训练数据

##### 什么是交叉验证？

==交叉验证==的目的是使用不重叠的测试集测试模型，该测试集的执行方式如下：

•  步骤1）将数据拆分为大小相等的k个子集

•  步骤2）选择一个子集进行测试，其余子集用来训练

•  步骤3）对其他k-1个子集重复步骤2

此过程称为==k交叉验证==，总的误差估计是误差估计的平均值。一种评估的标准方法是十倍交叉验证。大量实验表明，10个子集是获得准确估计的最佳选择。实际上，您可以重复十次交叉验证十次，然后计算结果的平均值，这有助于减少差异。

下一部分讨论正则化，如果您对TF 2代码主要感兴趣，则正则化是一个重要但可选的主题。如果您打算精通机器学习，则需要学习正则化。

#### 什么是正则化？

正则化有助于解决==过拟合问题==，当模型在训练数据上表现良好但在验证或测试数据上表现不佳时，就会发生过拟合问题。

正则化通过将==惩罚项==添加到成本函数来解决此问题，从而使用该惩罚项控制模型的复杂性。

正则化通常可用于：

•  大量变量

•  观测值/变量数的比率低

•  高多重共线性

正则化主要有两种类型：L1正则化（与MAE或差的绝对值有关）和L2正则化（与MSE或差的平方有关）。通常，L2的性能优于L1，并且在计算方面非常有效。

##### 机器学习和特征缩放

特征缩放标准化了数据功能范围。该步骤在数据预处理步骤中执行，部分原因是梯度下降得益于特征缩放。

假设数据符合标准正态分布，==标准化==包括减去平均值并除以每个数据点的标准差，从而得出==N（0,1）正态分布。==

##### 数据规范化与标准化

数据标准化是一种线性缩放技术。假设数据集具有值{X1，X2，。。。，Xn }以及以下术语：

Minx = Xi值的最小值

Maxx = Xi值的最大值

现在，如下计算一组新的Xi值：

Xi =（Xi – Minx）/ [Maxx – Minx]

现在新的Xi值被缩放到0到1之间。

#### 偏差-方差权衡

机器学习中的==偏差==可能是由于学习算法中的错误假设导致的错误。高偏差可能导致算法错过特征与目标输出之间的相关关系（拟合不足）。由于“嘈杂”的数据，不完整的功能集或有偏差的训练样本，可能会导致预测偏差。

偏差引起的误差是模型的预期（或平均）预测与要预测的正确值之间的差。多次重复模型构建过程，每次都收集新数据，并进行分析以生成新模型。由于基础数据集具有一定程度的随机性，因此所得模型具有一定范围的预测。偏差衡量了这些模型从正确值得出的预测的程度。

机器学习中的==方差==是平均值的平方偏差的期望值。高方差可能导致算法对训练数据中的随机噪声进行建模，而不是对预期的输出进行建模（又称过度拟合）。

==向模型添加参数会增加模型的复杂性，增加方差并减少偏差。处理偏差和方差就是处理拟合不足和拟合过度。==

由方差引起的误差是给定数据点的模型预测的方差。和以前一样，重复整个模型构建过程，方差是模型的不同“实例”之间给定点的预测变化的程度。

#### 测量模型的指标

R方是最常用的指标之一，它衡量数据与拟合的回归线（回归系数）的接近程度。R方值始终是0到100%之间的百分比。值0％表示该模型无法解释响应数据均值附近的变化。值100％表示该模型解释了响应数据均值附近的所有可变性。通常，==较高的R平方值表示较好的模型==。

##### R方的局限性

尽管较高的R方值是首选，但不一定总是好的值。同样，低R方值并不总是坏的。例如，用于预测人类行为的R方值通常小于50％。而且，R方不能确定系数估计和预测是否有偏差。另外，R方值不表示回归模型是否足够。因此，对于一个好的模型，可能有一个较低的R方值，而对于一个拟合程度较差的模型，可能有一个较高的R方值。结合残差图，其他模型统计信息和主题领域知识来评估R方值。

##### 混淆矩阵

最简单的形式是，混淆矩阵（也称为错误矩阵）是一种列式表，具有两行两列，其中包含错误肯定，错误否定，正确肯定和正确否定。2x2混淆矩阵中的四个条目可以标记如下：

TP：正确肯定

FP：错误肯定

TN：正确否定

FN：错误否定

混淆矩阵的对角线值是正确的预测，而反对角线值是不正确的预测。通常，较低的FP值优于FN值。例如，FP指示健康的人被错误地诊断为疾病，而FN指示不健康的人被错误地诊断为健康。

##### 精度与准确度与召回率

2x2混淆矩阵具有四个条目，分别代表正确和错误分类的各种组合。根据上一节中的定义，精度，准确度和召回率的定义由以下公式给出：(==精度的公式书中给错了？precision = TP/(TN + FP)==)
$$
精度：precision=TP/(TP+FP)\\
准确度：accuracy=(TP+TN)/(P+N)\\
召回率：recall=TP/(TP+FN)
$$
准确度可能是不可靠的指标，因为它会在不平衡的数据集中产生误导性的结果。当不同类别中的观察数显着不同时，它==对错误肯定和错误否定分类都具有同等的重要性==。例如，将癌症声明为良性要比错误地告知患者他们正在患癌症要糟糕。不幸的是，这两种情况的准确度并没有区别。

请记住，混淆矩阵可以是$n*n$矩阵，而不仅仅是2x2矩阵。例如，如果一个类有5个可能的值，则混淆矩阵为5x5矩阵，主对角线上的数字为“真正”结果。

##### ROC曲线

ROC（接收机工作特性）曲线是绘制TPR（即正确肯定率（即召回率）与FPR（即错误肯定率））的曲线。请注意，TNR（真实阴性率）也称为特异性。

以下链接包含使用SKLearn和Iris数据集的Python代码示例，以及用于绘制ROC的代码：

*https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html*

以下链接包含用于绘制ROC的各种Python代码示例：

*https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-*

#### 其他有用的统计术语

机器学习依靠大量统计量来评估模型的有效性，此处列出其中一些：

•  RSS

•  TSS

•  $R^2$

•  F1-score

•  p值

RSS，TSS和$R^2$的定义如下所示，其中$y_{1}$是最佳拟合线上的点的y坐标，而$y_{2}$是数据集中这些点的y值的平均值：

残差平方和$RSS =(y-y_{1})^2$

托尔平方和 $TSS=(y-y_{2})^2 $

$R ^ 2 = 1 - RSS / TSS$

##### 什么是F1-score？

F1-score是测试准确性的量度，被定义为==准确性和召回率的调和平均值==。以下是相关公式，其中p是精度，r是召回率，具体定义前文有交代。

$F1-score=\frac{2}{\frac{1}{r}+\frac{1}{p}} = \frac{2*p*r}{p+r}$

==？？？The best value of an F1 score is 0 and the worse value is 0.==一般来说F1-score越大越好。请记住，F1分数倾向于用于分类问题，而$R^2$值通常用于回归任务（例如线性回归）。

##### 什么是p值？

如果p值足够小（<0.005），则p值用于拒绝无效假设，这表示更高的显著性。回想一下，零假设声明一个因变量（比如y）和一个独立变量（比如x）之间没有相关性。p的阈值通常为1%或5%。

没有一个简单的公式来计算p值，p值总是介于0和1之间。事实上，p值是用来评估所谓“零假设”的统计量，它们是通过p值表或电子表格/统计软件计算出来的。

#### 什么是线性回归？

线性回归的目标是找到“代表”数据集的最佳拟合线。请记住两个关键点。首先，==最佳拟合线不一定穿过数据集中的所有（或大部分）点==。最佳拟合线的目的是使该线与数据集中的点的垂直距离最小。其次，==线性回归并不能确定最适合的多项式==：后者需要找到通过数据集中许多点的更高阶多项式。

而且，平面中的数据集可以包含两个或多个位于同一垂直线上的点，也就是说，这些点具有相同的x值。然而，一个函数不能穿过这样的一对点：如果两个点（X1，Y1）和（X2，Y2）具有相同的x值，则它们必须具有相同的Y值（即，Y1 = Y2）。另一方面，一个函数可以在同一水平线上有两个或多个点。

现在考虑一个散点图，该散点图上有许多点，这些点被“聚集”成细长的云状形状：最合适的线可能只与有限数量的点相交（实际上，最合适的线可能不相交相交的任何点）。

要记住的另一种情况：假设数据集包含位于同一条线上的一组点。例如，假设x值在集合{1,2,3，...，10}中，而y值在集合{2,4,6，...，20}中 。那么，最拟合线的方程为$y = 2*x + 0 $。在这种情况下，所有点都是共线的，也就是说它们位于同一条线上。

##### 线性回归与曲线拟合

假设数据集由（x，y）形式的n个数据点组成，并且这些数据点中没有两个具有相同的x值。然后根据一个著名的数学结果，有一个小于或等于n-1的度多项式经过这n个点（如果您真的很感兴趣，可以在在线文章中找到此陈述的数学证明） ）。例如，一条线是一个次数为1的多项式，它可以与平面中的任意一对非垂直点相交。对于平面中任何三点（并非全部在同一条线上），都有一个通过这些点的二次方程。

另外，有时可以使用低阶多项式。例如，考虑100个点的集合，其中x值等于y值：在这种情况下，线y = x（是一阶多项式）穿过所有100个点。

然而，请记住，到其上线“表示”的程度在平面中的点的集合取决于如何紧密这些点可以通过一条线，这是由测量来近似方差的点的（方差是一个统计数量）。点越共线，方差越小。相反，点越“分散”，方差越大。

##### 什么时候解是精确值？

尽管基于统计的解决方案为线性回归提供了封闭形式的解决方案，但神经网络却提供了近似的解决方案。这是由于以下事实：用于线性回归的机器学习算法包含一系列“收敛”到最佳值的近似值，这意味着机器学习算法会生成精确值的估计值。例如，对于2D平面的一组点而言，最佳拟合线的斜率m和y截距b在统计上具有封闭形式的解决方案，但只能通过机器学习算法来近似（确实存在例外，但他们很少见）。

请记住，即使“传统”线性回归的封闭式解决方案提供了m和b的精确值，有时您也只能使用精确值的近似值。例如，假设最佳拟合线的斜率m等于3的平方根，y截距b是2的平方根。如果您打算在源代码中使用这些值，则只能使用这两个数字的近似值。在相同的情况下，神经网络计算近似值m和b，而不管是否确切值的m和b是无理数，有理数或整数值。但是，机器学习算法更适合于复杂的非线性多维数据集，这超出了线性回归的能力。

举一个简单的例子，假设线性回归问题的闭式解产生m和b的整数或有理值。具体来说，让我们假设闭合形式的解分别得出最佳拟合线的斜率和y截距的值2.0和1.0。该行的等式如下所示：

$y = 2.0 * x + 1.0$

==但是==，来自训练神经网络的相应解决方案可能分别为斜率m和y轴截距b产生值2.0001和0.9997 ，作为最佳拟合线的m和b值。请始终牢记这一点，尤其是在训练神经网络时。

##### 什么是多元分析？

多元分析将欧氏平面中线的方程式推广到更高的维度，称为超平面而不是线。广义方程具有以下形式：

$y = w_{1} * x_{1} + w_{2} * x_{2} +。。。+ w_{n} * x_{n} + b$

在2D线性回归的情况下，您只需要找到斜率m和y轴截距b的值，而在多变量分析中，您需要找到$w_{1}$，$w_{2}$，...，$w_{n}$。请注意，多元分析是统计中的一个术语，在机器学习中，它通常被称为“广义线性回归”。

请记住，本书中与线性回归有关的大多数代码示例都涉及欧几里得平面中的2D点。

#### 其他类型的回归

线性回归找到了“代表”数据集的最佳拟合线，但是如果平面中的线与数据集的拟合度不高怎么办？使用数据集时，这是一个相关的问题。

线性回归的一些替代方法包括==二次方程，三次方程或高阶多项式==。但是，这些替代方案需要权衡取舍，我们将在后面讨论。

另一种可能性是一种涉及==分段线性函数==的混合方法，该函数包括一组线段。如果连接了连续的线段，则它是分段线性连续函数；否则，它是分段线性不连续函数。

因此，给定平面中的一组点，回归涉及解决以下问题：

•  哪种类型的曲线很好地拟合了数据？我们怎么知道？

•  其他类型的曲线是否更适合数据？

•  “最合适”是什么意思？

检查线是否适合数据的一种方法涉及视觉检查，但是这种方法不适用于二维以上的数据点。而且，这是一个主观决定，本章稍后将显示一些示例数据集。通过对数据集的直观检查，您可能会认为二次多项式或三次多项式（甚至更高阶）的多项式有可能更适合数据。但是，目视检查可能仅限于2D平面或三维上的点。

让我们推迟非线性场景，让我们假设一条线将非常适合数据。有一种众所周知的技术可以找到此类数据集的“最佳拟合”线，该技术涉及==最小化均方误差==（MSE），我们将在本章稍后讨论。

下一节将快速回顾平面中的线性方程，并提供一些图像说明线性方程的示例。