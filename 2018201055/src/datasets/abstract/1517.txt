The interest in large scale automated video surveillance systems and the interest in using cloud in supporting such systems has increased dramatically. Unfortunately, building such a large system requires huge resources (for processing and storage) and very high network bandwidth. This paper, proposes a framework for resources efficient intelligent automated surveillance framework that utilizes edge servers. In this framework, multiple video sources capture and send videos to a an edge server which performs an intelligent computer vision based cross-layer optimization of the video sources hardware resources and the network bandwidth. The network can be a wireless network and the sources can be mobile. The proposed solution changes the application rates and the required link layer parameters (the transmission opportunities in our case study) of the sending video sources according to the dynamic network conditions to maximize the overall accuracy of the computer vision algorithm(s) of interest in the system. The proposed framework utilizes an enhanced effective airtime estimation algorithm utilizing a Proportional Integral Differential (PID) controller that measure the available useful bandwidth in the network. Furthermore, we propose a bandwidth pruning mechanism to reach any desired tradeoff between the computer vision algorithm accuracy and the energy consumption of the video sources. We evaluate and present the effectiveness of the proposed framework, the effective airtime estimation algorithm, and the proposed bandwidth pruning mechanism, through extensive experiments using OPNET.
