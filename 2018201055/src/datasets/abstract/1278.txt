One of the important facets of effective social communication is Joint Attention (JA). However, children with Autism Spectrum Disorder (ASD) are often characterized by JA-related deficits, adversely affecting their social communication. In conventional interventions, therapists use different types of JA cues depending on one's capability to pick up the delivered cue. Though effective, conventional approaches suffer from restricted healthcare resources, cost, etc. With an increase in computational power, investigators are exploring alternative robot-based and computer-based techniques for JA skill training while delivering different types of JA cues. However, robot-assisted techniques are powerful but suffer from limitations such as high cost, restricted flexibility, etc. Thus, researchers are exploring the use of computer-based techniques for JA skill training since it can be controllable, flexible, cost-effective, more accessible, etc. With the advent of rich graphics, researchers are augmenting computer-based interfaces with Virtual Reality (VR) while designing Human-Computer Interaction (HCI)-based JA tasks. Given the importance of VR-enabled HCI-based JA training platform, studying the comparative potential of different types of JA cues (having varying information content) implemented using a VR-enabled HCI-based task platform is important. In this research work, we presented a VR-enabled HCI-based JA task platform that can deliver avatar-mediated and environment-triggered JA cues of varying information content. Results of a preliminary study with twenty typically developing and twenty age-matched children with ASD indicate differentiated implications of JA cues of varying information content on one's functional and physiological measures.
